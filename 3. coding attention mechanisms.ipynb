{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-09T13:21:05.721868Z",
     "start_time": "2024-02-09T13:21:04.722516Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    " attn_scores_2[i] = torch.dot(x_i, query)\n",
    "print(attn_scores_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T13:28:31.548178Z",
     "start_time": "2024-02-09T13:28:31.543720Z"
    }
   },
   "id": "e038f71d46c1c5d5",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.5500, 0.8700, 0.6600])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T13:28:48.305186Z",
     "start_time": "2024-02-09T13:28:48.295943Z"
    }
   },
   "id": "27452fc0e014dea6",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.9544"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.43*0.55+0.15*0.87+0.89*0.66"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T13:30:17.655755Z",
     "start_time": "2024-02-09T13:30:17.649300Z"
    }
   },
   "id": "846e28398723b04a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9544)\n",
      "tensor(0.9544)\n"
     ]
    }
   ],
   "source": [
    "res = 0.\n",
    "for idx, element in enumerate(inputs[0]):\n",
    " res += inputs[0][idx] * query[idx]\n",
    "print(res)\n",
    "print(torch.dot(inputs[0], query))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T13:33:08.730749Z",
     "start_time": "2024-02-09T13:33:08.720745Z"
    }
   },
   "id": "4b1e3b61b76bde84",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "print(\"Attention weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T13:38:25.547587Z",
     "start_time": "2024-02-09T13:38:25.541475Z"
    }
   },
   "id": "8d31aed474bafb6e",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    " return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "print(\"Attention weights:\", attn_weights_2_naive)\n",
    "print(\"Sum:\", attn_weights_2_naive.sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T13:59:45.461495Z",
     "start_time": "2024-02-09T13:59:45.453489Z"
    }
   },
   "id": "ec3f4150d585a916",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\",attn_weights_2.sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T14:02:47.989880Z",
     "start_time": "2024-02-09T14:02:47.976338Z"
    }
   },
   "id": "95ae940c443a396f",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1] # 2nd input token is the query\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i, x_i in enumerate(inputs):\n",
    " context_vec_2 += attn_weights_2[i]*x_i\n",
    "print(context_vec_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T14:13:54.387972Z",
     "start_time": "2024-02-09T14:13:54.381135Z"
    }
   },
   "id": "f229e05252134602",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.empty(6, 6)\n",
    "for i, x_i in enumerate(inputs):\n",
    " for j, x_j in enumerate(inputs):\n",
    "  attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "print(attn_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T14:21:14.102545Z",
     "start_time": "2024-02-09T14:21:14.094086Z"
    }
   },
   "id": "a5c6cf0ee54c1049",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "print(attn_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T14:24:34.029251Z",
     "start_time": "2024-02-09T14:24:34.018449Z"
    }
   },
   "id": "74e021d9d838f51e",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "print(attn_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T14:25:46.840265Z",
     "start_time": "2024-02-09T14:25:46.822138Z"
    }
   },
   "id": "64a1537f46c1c8f1",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2 sum: 1.0\n",
      "All row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "row_2_sum = sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
    "print(\"Row 2 sum:\", row_2_sum)\n",
    "print(\"All row sums:\", attn_weights.sum(dim=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T14:28:35.205617Z",
     "start_time": "2024-02-09T14:28:35.198046Z"
    }
   },
   "id": "bfe247b5a24b8468",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T14:30:03.147122Z",
     "start_time": "2024-02-09T14:30:03.119602Z"
    }
   },
   "id": "2d4a5048eb4d5b9d",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous 2nd context vector: tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous 2nd context vector:\", context_vec_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T14:30:58.583577Z",
     "start_time": "2024-02-09T14:30:58.576408Z"
    }
   },
   "id": "88127f68bb0311fc",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T03:47:40.112976Z",
     "start_time": "2024-02-10T03:47:40.102143Z"
    }
   },
   "id": "390f8ddf7d7f2f54",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T03:50:37.383074Z",
     "start_time": "2024-02-10T03:50:37.371263Z"
    }
   },
   "id": "732142dbb6d5721a",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(query_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T03:53:38.498398Z",
     "start_time": "2024-02-10T03:53:38.485984Z"
    }
   },
   "id": "7fe264a742359755",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T03:57:56.886261Z",
     "start_time": "2024-02-10T03:57:56.878333Z"
    }
   },
   "id": "381108c7bffcf9a9",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "keys_2 = keys[1]\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T04:03:06.491972Z",
     "start_time": "2024-02-10T04:03:06.489086Z"
    }
   },
   "id": "c761e1a890f567a2",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T # All attention scores for given query\n",
    "print(attn_scores_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T04:05:07.955788Z",
     "start_time": "2024-02-10T04:05:07.950838Z"
    }
   },
   "id": "2d73930889bfc15b",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k ** 0.5, dim=-1)\n",
    "print(attn_weights_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T04:09:00.305687Z",
     "start_time": "2024-02-10T04:09:00.289755Z"
    }
   },
   "id": "d91da70ca8970548",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T04:13:39.204414Z",
     "start_time": "2024-02-10T04:13:39.200354Z"
    }
   },
   "id": "fe92034ecb64b766",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 清单 3.1 紧凑的自注意力类\n",
    "import torch.nn as nn\n",
    "class SelfAttention_v1(nn.Module):\n",
    " def __init__(self, d_in, d_out):\n",
    "  super().__init__()\n",
    "  self.d_out = d_out\n",
    "  self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "  self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "  self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "  \n",
    " def forward(self, x):\n",
    "  keys = x @ self.W_key\n",
    "  queries = x @ self.W_query\n",
    "  values = x @ self.W_value\n",
    "  attn_scores = queries @ keys.T # omega\n",
    "  attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "  context_vec = attn_weights @ values\n",
    "  return context_vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:02:18.319543Z",
     "start_time": "2024-02-10T12:02:18.310596Z"
    }
   },
   "id": "21bf8056bcbf3278",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:02:19.760534Z",
     "start_time": "2024-02-10T12:02:19.747889Z"
    }
   },
   "id": "b7070a4d3aedbfaf",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 清单 3.2 使用 PyTorch Linear 层的自注意力类\n",
    "class SelfAttention_v2(nn.Module):\n",
    " def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "  super().__init__()\n",
    "  self.d_out = d_out\n",
    "  self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  \n",
    " def forward(self, x):\n",
    "  keys = self.W_key(x)\n",
    "  queries = self.W_query(x)\n",
    "  values = self.W_value(x)\n",
    "  attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "  context_vec = attn_weights @ values\n",
    "  return context_vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:10:29.576705Z",
     "start_time": "2024-02-10T12:10:29.562523Z"
    }
   },
   "id": "270bc1788cefddca",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5417, -0.0965],\n",
      "        [-0.5539, -0.1171],\n",
      "        [-0.5537, -0.1170],\n",
      "        [-0.5422, -0.1144],\n",
      "        [-0.5418, -0.1117],\n",
      "        [-0.5450, -0.1160]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:13:22.068735Z",
     "start_time": "2024-02-10T12:13:22.057782Z"
    }
   },
   "id": "a5e1ba7e5ed7c5",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1972, 0.1910, 0.1894, 0.1361, 0.1344, 0.1520],\n",
      "        [0.1476, 0.2164, 0.2134, 0.1365, 0.1240, 0.1621],\n",
      "        [0.1479, 0.2157, 0.2129, 0.1366, 0.1260, 0.1608],\n",
      "        [0.1505, 0.1952, 0.1933, 0.1525, 0.1375, 0.1711],\n",
      "        [0.1571, 0.1874, 0.1885, 0.1453, 0.1819, 0.1399],\n",
      "        [0.1473, 0.2033, 0.1996, 0.1500, 0.1160, 0.1839]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=1)\n",
    "print(attn_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:24:09.271660Z",
     "start_time": "2024-02-10T12:24:09.265999Z"
    }
   },
   "id": "b3ca63964c907b8c",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "block_size = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(block_size, block_size))\n",
    "print(mask_simple)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:25:55.293994Z",
     "start_time": "2024-02-10T12:25:55.285685Z"
    }
   },
   "id": "e2ac8634dfc249be",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1972, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1476, 0.2164, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1479, 0.2157, 0.2129, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1505, 0.1952, 0.1933, 0.1525, 0.0000, 0.0000],\n",
      "        [0.1571, 0.1874, 0.1885, 0.1453, 0.1819, 0.0000],\n",
      "        [0.1473, 0.2033, 0.1996, 0.1500, 0.1160, 0.1839]])\n"
     ]
    }
   ],
   "source": [
    "masked_simple = attn_weights * mask_simple\n",
    "print(masked_simple)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:27:11.040299Z",
     "start_time": "2024-02-10T12:27:11.038212Z"
    }
   },
   "id": "6efb9b166faeff",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4056, 0.5944, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2566, 0.3741, 0.3693, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2176, 0.2823, 0.2796, 0.2205, 0.0000, 0.0000],\n",
      "        [0.1826, 0.2178, 0.2191, 0.1689, 0.2115, 0.0000],\n",
      "        [0.1473, 0.2033, 0.1996, 0.1500, 0.1160, 0.1839]])\n"
     ]
    }
   ],
   "source": [
    "row_sums = masked_simple.sum(dim=1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(masked_simple_norm)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:28:46.793188Z",
     "start_time": "2024-02-10T12:28:46.791064Z"
    }
   },
   "id": "4d442befa542492f",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.9544, 1.4950,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.9422, 1.4754, 1.4570,   -inf,   -inf,   -inf],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937,   -inf,   -inf],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654,   -inf],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(block_size, block_size), diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:32:38.214801Z",
     "start_time": "2024-02-10T12:32:38.202736Z"
    }
   },
   "id": "bb4f9722005add63",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4056, 0.5944, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2566, 0.3741, 0.3693, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2176, 0.2823, 0.2796, 0.2205, 0.0000, 0.0000],\n",
      "        [0.1826, 0.2178, 0.2191, 0.1689, 0.2115, 0.0000],\n",
      "        [0.1473, 0.2033, 0.1996, 0.1500, 0.1160, 0.1839]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked / keys.shape[-1] ** 0.5, dim=1)\n",
    "print(attn_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:33:56.756768Z",
     "start_time": "2024-02-10T12:33:56.753300Z"
    }
   },
   "id": "70ca01bac3f6c449",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "example = torch.ones(6, 6)\n",
    "print(dropout(example))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:38:48.908398Z",
     "start_time": "2024-02-10T12:38:48.893239Z"
    }
   },
   "id": "11da79e5ffb13d16",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5132, 0.7482, 0.7386, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5646, 0.5592, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4357, 0.0000, 0.3378, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4065, 0.3991, 0.2999, 0.2320, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:40:19.600218Z",
     "start_time": "2024-02-10T12:40:19.591924Z"
    }
   },
   "id": "5cd73d29e74d7430",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T12:43:07.385168Z",
     "start_time": "2024-02-10T12:43:07.378830Z"
    }
   },
   "id": "d907ec60386aeb67",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 清单 3.3 紧凑的因果注意力类\n",
    "class CasualAttention(nn.Module):\n",
    " def __init__(self, d_in, d_out, block_size, dropout, qkv_bias=False):\n",
    "  super().__init__()\n",
    "  self.d_out = d_out\n",
    "  self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  self.dropout = nn.Dropout(dropout)\n",
    "  self.register_buffer('mask', torch.triu(torch.ones(block_size, block_size), diagonal=1))\n",
    " \n",
    " def forward(self, x):\n",
    "  b, num_tokens, d_in = x.shape # C New batch dimension b\n",
    "  keys = self.W_key(x)\n",
    "  queries = self.W_query(x)\n",
    "  values = self.W_value(x)\n",
    "  \n",
    "  attn_scores = queries @ keys.transpose(1, 2)\n",
    "  attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "  attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=1)\n",
    "  \n",
    "  context_vec = attn_weights @ values\n",
    "  return context_vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:00:04.463425Z",
     "start_time": "2024-02-10T13:00:04.453030Z"
    }
   },
   "id": "2bf948898895ca2c",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "block_size = batch.shape[1]\n",
    "ca = CasualAttention(d_in, d_out, block_size, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:00:04.804524Z",
     "start_time": "2024-02-10T13:00:04.795993Z"
    }
   },
   "id": "17b6effd1ebd1fdc",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 清单 3.4 实现多头注意力的包装类\n",
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    " def __init__(self, d_in, d_out, block_size, dropout, num_heads, qkv_bias=False):\n",
    "  super().__init__()\n",
    "  self.heads = nn.ModuleList([CasualAttention(d_in, d_out, block_size, dropout, qkv_bias) for _ in range(num_heads)])\n",
    " def forward(self, x):\n",
    "  return torch.cat([head(x) for head in self.heads], dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:08:52.279589Z",
     "start_time": "2024-02-10T13:08:52.262514Z"
    }
   },
   "id": "7185e461112bf393",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0844,  0.0414,  0.0766,  0.0171],\n",
      "         [-0.2264, -0.0039,  0.2143,  0.1185],\n",
      "         [-0.4163, -0.0564,  0.3878,  0.2453],\n",
      "         [-0.5014, -0.1011,  0.4992,  0.3401],\n",
      "         [-0.7754, -0.1867,  0.7387,  0.4868],\n",
      "         [-1.1632, -0.3303,  1.1224,  0.8460]],\n",
      "\n",
      "        [[-0.0844,  0.0414,  0.0766,  0.0171],\n",
      "         [-0.2264, -0.0039,  0.2143,  0.1185],\n",
      "         [-0.4163, -0.0564,  0.3878,  0.2453],\n",
      "         [-0.5014, -0.1011,  0.4992,  0.3401],\n",
      "         [-0.7754, -0.1867,  0.7387,  0.4868],\n",
      "         [-1.1632, -0.3303,  1.1224,  0.8460]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "block_size = batch.shape[1] # This is the number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(d_in, d_out, block_size, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:12:58.206671Z",
     "start_time": "2024-02-10T13:12:58.185245Z"
    }
   },
   "id": "ee01928de9e9da58",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 清单 3.5 高效的多头注意力类\n",
    "class MultiHeadAttention(nn.Module):\n",
    " def __init__(self, d_in, d_out, block_size, dropout, num_heads, qkv_bias=False):\n",
    "  super().__init__()\n",
    "  assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "  \n",
    "  self.d_out = d_out\n",
    "  self.num_heads = num_heads\n",
    "  self.head_dim = d_out // num_heads\n",
    "  self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  self.out_proj = nn.Linear(d_out, d_out)\n",
    "  self.dropout = nn.Dropout(dropout)\n",
    "  self.register_buffer('mask', torch.triu(torch.ones(block_size, block_size), diagonal=1))\n",
    "  \n",
    " def forward(self, x):\n",
    "  b, num_tokens, d_in = x.shape\n",
    "  keys = self.W_key(x)\n",
    "  queries = self.W_query(x)\n",
    "  values = self.W_value(x)\n",
    "  \n",
    "  keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "  values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "  queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "  \n",
    "  keys = keys.transpose(1, 2)\n",
    "  queries = queries.transpose(1, 2)\n",
    "  values = values.transpose(1, 2)\n",
    "  \n",
    "  attn_scores = queries @ keys.transpose(2, 3)\n",
    "  mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "  mask_unsqueeze = mask_bool.unsqueeze(0).unsqueeze(0)\n",
    "  attn_scores.masked_fill_(mask_unsqueeze, -torch.inf)\n",
    "  \n",
    "  attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "  attn_weights = self.dropout(attn_weights)\n",
    "  \n",
    "  context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "  \n",
    "  context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "  context_vec = self.out_proj(context_vec)\n",
    "  return context_vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:26:23.078911Z",
     "start_time": "2024-02-10T13:26:23.068110Z"
    }
   },
   "id": "c2b4a8fe0c8624f4",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
    "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
    "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
    " \n",
    "                   [[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
    "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:31:18.981630Z",
     "start_time": "2024-02-10T13:31:18.970801Z"
    }
   },
   "id": "b89d4211b1e247ad",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.3208, 1.1631, 1.2879],\n",
      "          [1.1631, 2.2150, 1.8424],\n",
      "          [1.2879, 1.8424, 2.0402]],\n",
      "\n",
      "         [[0.4391, 0.7003, 0.5903],\n",
      "          [0.7003, 1.3737, 1.0620],\n",
      "          [0.5903, 1.0620, 0.9912]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a @ a.transpose(2, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:33:32.503394Z",
     "start_time": "2024-02-10T13:33:32.485512Z"
    }
   },
   "id": "b0319aa83adda6ab",
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First head:\n",
      " tensor([[1.3208, 1.1631, 1.2879],\n",
      "        [1.1631, 2.2150, 1.8424],\n",
      "        [1.2879, 1.8424, 2.0402]])\n",
      "Second head:\n",
      " tensor([[0.4391, 0.7003, 0.5903],\n",
      "        [0.7003, 1.3737, 1.0620],\n",
      "        [0.5903, 1.0620, 0.9912]])\n"
     ]
    }
   ],
   "source": [
    "first_head = a[0, 0, :, :]\n",
    "first_res = first_head @ first_head.T\n",
    "print(\"First head:\\n\", first_res)\n",
    "\n",
    "second_head = a[0, 1, :, :]\n",
    "second_res = second_head @ second_head.T\n",
    "print(\"Second head:\\n\", second_res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:34:40.829005Z",
     "start_time": "2024-02-10T13:34:40.801406Z"
    }
   },
   "id": "6e03068419da598d",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_size, block_size, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, block_size, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:39:01.822105Z",
     "start_time": "2024-02-10T13:39:01.815112Z"
    }
   },
   "id": "ae96007e010f2e2d",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7d88e1f680192074"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
